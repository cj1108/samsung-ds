{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Tensorflow Basic\n",
    "\n",
    "이 실습에서는 Tensorflow에서 가장 핵심이 되는 **텐서**를 만들고 조작하는 함수를 알아보도록 하겠습니다. Tensorflow 내에서 텐서는 `Tensor` 클래스를 통해 구현됩니다. 필수는 아니지만, 실습을 하면서 Tensor의 구체적인 정보가 필요하신 분들은 다음 [**링크**](https://www.tensorflow.org/guide/tensor)를 참조해주세요. 실습 진행에 필수적으로 \n",
    "\n",
    "Tensorflow에서 사용하는 함수들에 대해선 다음 링크를 참조해주세요. 텐서 실습시에 필요한 함수를 찾아보기에 유용할 것입니다.\n",
    "\n",
    "[**Tensorflow API 문서**](https://www.tensorflow.org/api_docs/python/tf#functions_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 텐서가 완전히 같은지를 판별하는 함수입니다.\n",
    "def compare_tensors(x, y):\n",
    "    diff = len(tf.where(tf.math.equal(x, y) == False))\n",
    "    \n",
    "    if diff == 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Constant Tensors\n",
    "\n",
    "모든 값이 **상수**인 텐서를 만드는 함수를 알아봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t1]\n",
      " tf.Tensor(8, shape=(), dtype=int32)\n",
      "\n",
      "[t2]\n",
      ": tf.Tensor(\n",
      "[[0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0.]], shape=(3, 5), dtype=float32)\n",
      "\n",
      "[t3]\n",
      " tf.Tensor(\n",
      "[[[1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1.]]\n",
      "\n",
      " [[1. 1. 1. 1. 1. 1.]\n",
      "  [1. 1. 1. 1. 1. 1.]]], shape=(4, 2, 6), dtype=float32)\n",
      "\n",
      "[t4]\n",
      " tf.Tensor(\n",
      "[[[7 7 7 7]\n",
      "  [7 7 7 7]\n",
      "  [7 7 7 7]\n",
      "  [7 7 7 7]\n",
      "  [7 7 7 7]]\n",
      "\n",
      " [[7 7 7 7]\n",
      "  [7 7 7 7]\n",
      "  [7 7 7 7]\n",
      "  [7 7 7 7]\n",
      "  [7 7 7 7]]], shape=(2, 5, 4), dtype=int32)\n",
      "\n",
      "[t5]\n",
      " tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#################################################\n",
    "# TODO: 8의 값을 가지는 스칼라 텐서를 만드세요.\n",
    "\n",
    "t1 = tf.constant(8)\n",
    "#################################################\n",
    "\n",
    "print('[t1]\\n', t1)\n",
    "print()\n",
    "\n",
    "#################################################\n",
    "# TODO: 0의 값을 가지는 (3 X 5) 텐서를 만드세요.\n",
    "#       코드는 한줄로만 작성해야 합니다.\n",
    "\n",
    "t2 = tf.zeros((3, 5))\n",
    "#################################################\n",
    "\n",
    "print('[t2]\\n:', t2)\n",
    "print()\n",
    "\n",
    "#########################################################\n",
    "# TODO: 모든 원소의 값이 1인 (4 X 2 X 6) 텐서를 만드세요.\n",
    "#       코드는 한줄로만 작성해야 합니다. \n",
    "\n",
    "t3 = tf.ones((4, 2, 6))\n",
    "#########################################################\n",
    "\n",
    "print('[t3]\\n', t3)\n",
    "print()\n",
    "\n",
    "################################################################################\n",
    "# TODO: 모든 원소의 값이 7인 (2 X 5 X 4) 텐서를 만드세요.\n",
    "#       코드는 한줄로만 작성해야 합니다. 위의 함수들과는 다른 함수를 사용해야 합니다.\n",
    "\n",
    "t4 = tf.fill((2, 5, 4), value=7)\n",
    "################################################################################\n",
    "\n",
    "print('[t4]\\n', t4)\n",
    "print()\n",
    "\n",
    "############################################################\n",
    "# TODO: [1, 2, 3, 4, 5, 6]의 값으로 (2 X 3) 텐서를 만드세요.\n",
    "#       반드시 [1, 2, 3, 4, 5, 6]을 input으로 주되,\n",
    "#       이를 (2 X 3) 으로 바꿀 수 있는 argument를 찾아보세요.\n",
    "#       코드는 한줄로만 작성해야 합니다.\n",
    "\n",
    "t5 = tf.constant([1, 2, 3, 4, 5, 6], shape=(2, 3))\n",
    "############################################################\n",
    "\n",
    "print('[t5]\\n', t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Random Tensors\n",
    "\n",
    "텐서의 각 원소를 **임의**로 지정하는 함수를 알아봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[rand_t1]\n",
      " tf.Tensor(\n",
      "[[-2.4046578e+00 -2.3890927e+00  1.7833508e+00 -1.5023217e+00]\n",
      " [-5.4486282e-04 -5.0134611e-01 -7.7926201e-01 -2.5646713e+00]\n",
      " [-4.3001470e-01 -1.0267419e+00  1.8098091e+00 -9.2778307e-01]\n",
      " [-6.2344633e-02 -8.9523911e-01  3.3514613e-01 -2.5981575e-01]\n",
      " [ 3.2710505e-01 -1.7180382e+00 -3.1354606e-01 -2.0487127e+00]\n",
      " [ 9.0171307e-01 -4.1337857e-01 -1.3884579e+00 -3.4358630e-01]\n",
      " [-2.8841323e-01  1.1770872e-01 -7.2498763e-01  1.0482235e+00]], shape=(7, 4), dtype=float32)\n",
      "\n",
      "[rand_t2]\n",
      " tf.Tensor(\n",
      "[[[0.62767375 2.7832541  1.5146334 ]\n",
      "  [2.6936622  1.1480434  0.06829405]\n",
      "  [1.2047725  0.21837616 0.33334315]\n",
      "  [1.7212479  1.597661   1.5285648 ]]\n",
      "\n",
      " [[0.80363095 1.7277621  2.7257144 ]\n",
      "  [0.90650225 0.37655568 1.037217  ]\n",
      "  [1.932503   2.6068726  1.3043493 ]\n",
      "  [1.4198098  2.3080592  1.7486658 ]]\n",
      "\n",
      " [[0.9092431  2.4248214  0.30236614]\n",
      "  [2.3175368  1.078062   2.1176138 ]\n",
      "  [0.337762   2.9588685  0.76999104]\n",
      "  [1.8738971  1.1449202  1.4800705 ]]\n",
      "\n",
      " [[1.0190209  0.28985596 2.589539  ]\n",
      "  [1.8622591  0.7923074  2.6210797 ]\n",
      "  [1.1744038  0.27507985 2.4065404 ]\n",
      "  [0.86897635 0.57394516 0.5433072 ]]\n",
      "\n",
      " [[2.0293865  0.9541966  1.6304383 ]\n",
      "  [0.3771429  2.6931145  1.4271955 ]\n",
      "  [2.7020853  0.9948703  2.2708035 ]\n",
      "  [0.12503886 2.7474682  0.8949369 ]]], shape=(5, 4, 3), dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed = 3921\n",
    "\n",
    "#######################################################################\n",
    "# TODO: 평균 0, 표준편차 1인 정규 분포에서 생성된 (7 X 4) 텐서를 만드세요.\n",
    "#        seed 값을 꼭 위의 변수로 설정해주세요!\n",
    "\n",
    "rand_t1 = tf.random.normal((7, 4), seed=seed)\n",
    "#######################################################################\n",
    "\n",
    "print('[rand_t1]\\n', rand_t1)\n",
    "print()\n",
    "\n",
    "####################################################################################\n",
    "# TODO: 최소값 0, 최대값 3인 균등(uniform) 분포에서 생성된 (5 X 4 X 3) 텐서를 만드세요.\n",
    "#       seed 값을 꼭 위의 변수로 설정해주세요!\n",
    "\n",
    "rand_t2 = tf.random.uniform((5, 4, 3), minval=0, maxval=3)\n",
    "####################################################################################\n",
    "\n",
    "print('[rand_t2]\\n', rand_t2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Tensor Arithmetic\n",
    "\n",
    "두개 이상의 텐서의 **사칙연산과 행렬곱**을 구하는 함수를 알아봅니다.\n",
    "\n",
    "더불어, 하나의 텐서의 모든 원소들의 **합, 평균, 최대값**을 구하는 함수 또한 알아봅니다.\n",
    "\n",
    "**Hint**: 합, 평균, 최대의 경우에는 모든 원소들을 하나의 값으로 **감소(reduce)** 시키는 것이므로 이것에 유의하여 함수를 찾아보세요. 이들은 주로 [**tf.math**](https://www.tensorflow.org/api_docs/python/tf/math) 모듈 내에 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PASS> add_1 and add_2 are same!\n",
      "\n",
      "<PASS> mul_1 and mul_2 are same!\n",
      "\n",
      "<PASS> mat_mul_1 and mat_mul_2 are same!\n",
      "\n",
      "[mean_mat_mul_1]: tf.Tensor(355, shape=(), dtype=int32)\n",
      "[sum_mat_mul_1]: tf.Tensor(6390, shape=(), dtype=int32)\n",
      "[max_mat_mul_1]: tf.Tensor(660, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#####################################################################\n",
    "# TODO: 1부터 12까지의 값을 연속적으로 가지는 (3 X 4) 텐서를 만드세요.\n",
    "#       값을 연속으로 생성할 수 있는 Tensorflow 내의 함수를 사용하세요.\n",
    "\n",
    "t1 = tf.constant(tf.range(1, 13), shape=(3, 4))\n",
    "#####################################################################\n",
    "\n",
    "#####################################################################\n",
    "# TODO: 13부터 24까지의 값을 연속적으로 가지는 (3 X 4) 텐서를 만드세요.\n",
    "#       값을 연속으로 생성할 수 있는 Tensorflow 내의 함수를 사용하세요.\n",
    "\n",
    "t2 = tf.constant(tf.range(13, 25), shape=(3, 4))\n",
    "#####################################################################\n",
    "\n",
    "#####################################################################\n",
    "# TODO: t1과 t2를 원소별로(element-wise) 더한 텐서를 구하세요.\n",
    "# add_1과 add_2를 서로 다른 방식으로 계산하되, 둘의 결과는 같아야 합니다.\n",
    "\n",
    "add_1 = t1 + t2\n",
    "add_2 = tf.add(t1, t2)\n",
    "#####################################################################\n",
    "\n",
    "assert compare_tensors(add_1, add_2)\n",
    "print('<PASS> add_1 and add_2 are same!\\n')\n",
    "\n",
    "#####################################################################\n",
    "# TODO: t1과 t2를 원소별로 곱한 텐서를 구하세요.\n",
    "# mul_1과 mul_2를 서로 다른 방식으로 계산하되, 둘의 결과는 같아야 합니다.\n",
    "\n",
    "mul_1 = t1 * t2\n",
    "mul_2 = tf.multiply(t1, t2)\n",
    "#####################################################################\n",
    "\n",
    "assert compare_tensors(mul_1, mul_2)\n",
    "print('<PASS> mul_1 and mul_2 are same!\\n')\n",
    "\n",
    "#####################################################################\n",
    "# TODO: 1부터 24까지의 값을 연속적으로 가지는 (4 X 6) 텐서를 만드세요.\n",
    "#       값을 연속으로 생성할 수 있는 Tensorflow 내의 함수를 사용하세요.\n",
    "\n",
    "t3 = tf.constant(tf.range(1, 25), shape=(4, 6))\n",
    "#####################################################################\n",
    "\n",
    "#############################################################################\n",
    "# TODO: t1과 t3 사이의 행렬곱(matrix multiplication)을 구하세요.\n",
    "# mat_mul_1과 mat_mul_2를 서로 다른 방식으로 계산하되, 둘의 결과는 같아야 합니다.\n",
    "\n",
    "mat_mul_1 = t1 @ t3\n",
    "mat_mul_2 = tf.matmul(t1, t3)\n",
    "#####################################################################\n",
    "\n",
    "assert compare_tensors(mat_mul_1, mat_mul_2)\n",
    "print('<PASS> mat_mul_1 and mat_mul_2 are same!\\n')\n",
    "\n",
    "###############################################################\n",
    "# TODO: mat_mul_1의 전체 평균과 전체 합, 최대값을 각각 구하세요.\n",
    "\n",
    "mean_mat_mul_1 = tf.math.reduce_mean(mat_mul_1)\n",
    "sum_mat_mul_1 = tf.math.reduce_sum(mat_mul_1)\n",
    "max_mat_mul_1 = tf.math.reduce_max(mat_mul_1)\n",
    "###############################################################\n",
    "\n",
    "print('[mean_mat_mul_1]:', mean_mat_mul_1)\n",
    "print('[sum_mat_mul_1]:', sum_mat_mul_1)\n",
    "print('[max_mat_mul_1]:', max_mat_mul_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Tensor Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[t1_reshape1]\n",
      " tf.Tensor(\n",
      "[[ 1  2  3  4  5  6]\n",
      " [ 7  8  9 10 11 12]\n",
      " [13 14 15 16 17 18]\n",
      " [19 20 21 22 23 24]], shape=(4, 6), dtype=int32)\n",
      "\n",
      "[t1_reshape2]\n",
      " tf.Tensor(\n",
      "[[ 1  2  3  4  5  6  7  8]\n",
      " [ 9 10 11 12 13 14 15 16]\n",
      " [17 18 19 20 21 22 23 24]], shape=(3, 8), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#######################################################################\n",
    "# TODO: 1부터 24까지의 값을 연속적으로 가지는 (2 X 3 X 4) 텐서를 만드세요.\n",
    "\n",
    "t1 = tf.constant(tf.range(1, 25), shape=(2, 3, 4))\n",
    "#######################################################################\n",
    "\n",
    "###########################################\n",
    "# TODO: t1 텐서를 (4 X 6) 텐서로 변환하세요.\n",
    "\n",
    "t1_reshape1 = tf.reshape(t1, [4, 6])\n",
    "###########################################\n",
    "\n",
    "print('[t1_reshape1]\\n', t1_reshape1)\n",
    "print()\n",
    "\n",
    "###################################################\n",
    "# TODO: t1 텐서를 행이 3개인 2차원 텐서로 변환하세요.\n",
    "#       행 개수만 지정해야 합니다!\n",
    "\n",
    "t1_reshape2 = tf.reshape(t1, [3, -1])\n",
    "###################################################\n",
    "\n",
    "print('[t1_reshape2]\\n', t1_reshape2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Variable Tensor\n",
    "\n",
    "**Variable 텐서**는 변화하는 값을 저장하기 위한 클래스입니다. 지금까지 사용한 함수로 생성된 텐서는 한번 생성되면 그 값을 변화시킬 수 없습니다. 하지만 모델이 학습되기 위해서는 모델을 구성하는 **weight 텐서**가 변화해야 하기 때문에 이때는 값이 **변화하는** 텐서가 필요합니다. 따라서 이 경우에 사용하는 텐서가 바로 **Variable** 텐서입니다.\n",
    "\n",
    "Variable 텐서는 `tensorflow` 내의 `Variable` 클래스를 이용하여 생성할 수 있습니다. 이 클래스는 `Tensor` 클래스를 기반으로 구현되었기 때문에 기존 텐서에서 사용하였던 연산들을 똑같이 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[var_t]:\n",
      " <tf.Variable 'Variable:0' shape=(3, 3) dtype=int32, numpy=\n",
      "array([[1, 2, 3],\n",
      "       [4, 5, 6],\n",
      "       [7, 8, 9]], dtype=int32)>\n",
      "\n",
      "[var_t2]\n",
      " <tf.Variable 'Variable:0' shape=(2, 2) dtype=int32, numpy=\n",
      "array([[1, 2],\n",
      "       [3, 4]], dtype=int32)>\n",
      "\n",
      "[var_t3]\n",
      " <tf.Variable 'UnreadVariable' shape=(2, 2) dtype=int32, numpy=\n",
      "array([[5, 6],\n",
      "       [7, 8]], dtype=int32)>\n",
      "\n",
      "[var_t4]\n",
      " <tf.Variable 'UnreadVariable' shape=(2, 2) dtype=int32, numpy=\n",
      "array([[ 7,  9],\n",
      "       [11, 13]], dtype=int32)>\n",
      "\n",
      "[var_t5]\n",
      " <tf.Variable 'UnreadVariable' shape=(2, 2) dtype=int32, numpy=\n",
      "array([[6, 6],\n",
      "       [6, 6]], dtype=int32)>\n"
     ]
    }
   ],
   "source": [
    "######################################################################\n",
    "# TODO: 1부터 9까지의 값을 순서대로 가지는 3 x 3 Variable 텐서를 만드세요\n",
    "\n",
    "var_t = tf.Variable([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
    "######################################################################\n",
    "\n",
    "print('[var_t]:\\n', var_t)\n",
    "print()\n",
    "\n",
    "################################################################\n",
    "# TODO: constant를 이용해 1부터 4까지의 값을 가지는 텐서를 만들고\n",
    "#       Variable 텐서로 변환하세요\n",
    "\n",
    "cons_t = tf.constant([[1, 2], [3, 4]])\n",
    "var_t2 = tf.Variable(cons_t)\n",
    "################################################################\n",
    "\n",
    "print('[var_t2]\\n', var_t2)\n",
    "print()\n",
    "\n",
    "########################################################################\n",
    "# TODO: 위에서 생성한 var_t2의 값을 5에서 8까지의 값이 들어가도록 바꾸세요\n",
    "\n",
    "var_t3 = var_t2.assign([[5, 6], [7, 8]])\n",
    "########################################################################\n",
    "\n",
    "print('[var_t3]\\n', var_t3)\n",
    "print()\n",
    "\n",
    "############################################################\n",
    "# TODO: var_t3에 [[2, 3], [4, 5]]로 이루어진 텐서를 더하세요\n",
    "#       반드시 Variable 텐서에 사용되는 함수를 이용해야 합니다.\n",
    "\n",
    "var_t4 = var_t3.assign_add([[2, 3], [4, 5]])\n",
    "############################################################\n",
    "\n",
    "print('[var_t4]\\n', var_t4)\n",
    "print()\n",
    "\n",
    "############################################################\n",
    "# TODO: var_t4에 [[1, 3], [5, 7]]로 이루어진 텐서를 빼세요\n",
    "#       반드시 Variable 텐서에 사용되는 함수를 이용해야 합니다.\n",
    "\n",
    "var_t5 = var_t4.assign_sub([[1, 3], [5, 7]])\n",
    "############################################################\n",
    "\n",
    "print('[var_t5]\\n', var_t5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Gradient\n",
    "\n",
    "Variable 텐서를 사용하는 가장 큰 이유는 Gradient 계산, 즉 미분을 하기 위함입니다. 앞서 소개해드린 대로 모델의 학습을 위해 **손실 함수(Loss Function)** 을 정의하고 이를 최적화하기 위해 Automatic Differentiation을 수행하는데, 이번 실습에서는 Tensorflow에서 미분을 관리하는 `GradientTape` 이라는 것을 알아보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 다음은 GradientTape을 어떻게 사용하는지에 대한 간단한 예시입니다.\n",
    "# 여기서는 x가 Variable 텐서가 아닌 일반 텐서임을 유의해주세요.\n",
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(x) # x가 Variable이 아니기 때문에 x를 GradientTape이 추적할 수 있도록 해줍니다.\n",
    "    y = x * x # y = x ^ 2\n",
    "    \n",
    "dy_dx = tape.gradient(y, x) # dy = 2x\n",
    "print(dy_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dw / dz: tf.Tensor([68. 68.], shape=(2,), dtype=float32)\n",
      "dw / dx: tf.Tensor([408. 408.], shape=(2,), dtype=float32)\n",
      "dw / dy: tf.Tensor([680. 680.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "######################################################################################\n",
    "# TODO: z = x ^ 2 + y ^ 2와 w = z ^ 2 함수를 구현한 뒤에 dw_dz, dw_dx, dw_dy를 구하세요.\n",
    "# x와 y는 각각 [3.0, 3.0]과 [5.0, 5.0]의 초기값을 갖는 Variable 텐서여야 합니다.\n",
    "\n",
    "x = tf.Variable([3.0, 3.0])\n",
    "y = tf.Variable([5.0, 5.0])\n",
    "\n",
    "# gradient() 함수를 여러번 사용하기 위해서는 persistent=True를 설정해야 합니다.\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    # Variable 텐서를 사용하면 watch() 함수는 필요하지 않습니다.\n",
    "    z = tf.multiply(x, x) + tf.multiply(y, y)\n",
    "    w = tf.multiply(z, z)\n",
    "\n",
    "print('dw / dz:', tape.gradient(w, z)) # z에 대한 w의 미분\n",
    "print('dw / dx:', tape.gradient(w, x)) # x에 대한 w의 미분\n",
    "print('dw / dy:', tape.gradient(w, y)) # y에 대한 w의 미분\n",
    "######################################################################################"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
